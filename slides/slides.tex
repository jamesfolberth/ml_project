\documentclass{beamer}
\usetheme{Berlin}
\usepackage{amsmath}
\usepackage{lmodern}
\usepackage{hyperref}
\usepackage{color}

\title[Science Questions]{Answering Questions about Science - Milksteak}
\subtitle[Application]{Quiz Bowl Science}
\author[Cowley, Folberth, Reiersen, Wiley]{Andrew Cowley, James Folberth, Derek Reiersen, Benjamin Wiley}
\institute[CU Boulder]{
  Final Project\\
  CSCI 5622: Machine Learning\\[1ex]
University of Colorado at Boulder
}
\date[December 2015]{December 15, 2015}

\begin{document}
\begin{frame}[plain]
  \titlepage
	\title[Science Questions]{Answering Questions about Science}
\end{frame}

%----------------------------------------------------------------------------------------------------------------------------------

% Our talk is short; don't want to spend time on an overview.
%\begin{frame}{Overview}
%	\tableofcontents
%\end{frame}


\begin{frame}{Problem Statement}
   \begin{itemize}
      \item We're given a bunch of multiple choice science questions, where each answer (almost) corresponds to a Wikipedia page title.\\
      \item The goal is to predict the correct answer to new questions.
   \end{itemize}

   Example: ``This phenomenon occurs twice as quickly in the Moran model as in the Wright-Fisher model.''
   \begin{enumerate}
      \item Genetic drift
      \item Hamiltonian (quantum mechanics)
      \item Georg Wilhelm Friedrich Hegel
      \item Group (mathematics)
   \end{enumerate}
\end{frame}


%----------------------------------------------------------------------------------------------------------------------------------

\section{Methods}

%\subsection{A little NLP}
\begin{frame}{A little NLP}
   \begin{itemize}
      \item Download and cache Wikipedia summary, categories, full text, etc.
      \item Lemmatize question strings and Wiki summaries (shorter than full text).
      \item Try to emphasize proper nouns (e.g. Moran model).
      \item Count tokens and build feature vector.
   \end{itemize}
\end{frame}

%\subsection{NLP to Eliminate Answers}
\begin{frame}{NLP to Eliminate Answers}
   \begin{itemize}
      \item Antibodies that localize to {\color{red}this} {\color{green}organelle} are associated with Sjogren\'s ("SHOW-grenz") syndrome, and a deficiency of a phosphatase localized to it causes Lowe\'s syndrome.

	(a) {\color{green}Golgi Apparatus} (b) Apoptosis (c) {\color{green}Peroxisome} (d) Collagen

      \item {\color{red}This} {\color{green}phylum's} members have a pair of pouches that split from the archenteron, with each pouch constricting into three portions. 

	(a) Xylem (b) {\color{green}Echinoderm} (c) Sponge (d) Mitochondrian
   \end{itemize}
\end{frame}

%\subsection{NLP to Eliminate Answers}
\begin{frame}{NLP to Eliminate Answers}
   \begin{itemize}
      \item NLTK part-of-speech tagger to determine answer category
      \item Use Wikipedia data along with the PyGoogle module to gain insight answer-category relationship
      \item Eliminate options with a very low false positive rate
   \end{itemize}
\end{frame}

%\subsection{Cosine Similarity}
\begin{frame}{Cosine Similarity}
  A standard method to compare documents is to use the cosine similarity of feature vectors:

  \[ \text{similarity}_{ij} = \cos\theta_{ij} = \dfrac{\langle x_i, x_j\rangle}{\|x_i\| \|x_j\|}. \] 

  Which features are ``turned on'' together?\\

  Using only this gets about $70\%$ on our development set.
\end{frame}


% Looks like adding the proper noun features isn't helping much here.
% this is also reflected by removing the NNP features entirely; we still score ~70% on the dev set
% The questions are feature dense (e.g. just have to find ``Birch-Murnaghan''), but we're not using this fully
% Not many links on Bulk modulus page.  If we were better at NLP, we might try to search Wikipedia for ``Birch-Murnaghan'' or ``Cauchys Number''.  That seems hard...
\begin{frame}{Cosine Similarity}
   Example: ``The Birch-Murnaghan equation of state takes volume and this parameter at zero pressure as its arguments, and Cauchys Number in compressible flows is inversely proportional to this quantity.''\\[1em]
   {\color{green}Correct}: Bulk modulus\\
   {\color{red}Our Answer}: Hamiltonian (quantum mechanics)\\[1em]

   ``equation'' and ``state'' occur very frequently in the Hamiltonian page (long), but infrequently in Bulk modulus page (short).\\
\end{frame}

\begin{frame}{Logistic Regression Baseline}
   \begin{itemize}
      \item Use training question with correct answer as training data
      \item 62 percent baseline
      \item Improve by using wikipedia summary sentences as additional training data
      \item 72 percent on cross-validation, 65 percent on kaggle
   \end{itemize}
\end{frame}

%----------------------------------------------------------------------------------------------------------------------------------

% Surprisingly, using LDA gets the Bulk modulus v. Hamiltonian question right. (using 75%-25% split).
%\subsection{Topic Model}
\begin{frame}{Topic Model}
   \begin{itemize}
      \item We also tried to use a topic model to categorize the Wiki pages.
      \item Doesn't work well on its own, but helps other methods a little bit.
      \item Probably just picking the low-hanging fruit.
   \end{itemize}
\end{frame}

%----------------------------------------------------------------------------------------------------------------------------------

%\subsection{Features}
\begin{frame}{Features}

\end{frame}

%----------------------------------------------------------------------------------------------------------------------------------

\section{Optimization}

%\subsection{Logistic Regression}
\begin{frame}{Logistic Regression}

\end{frame}

%----------------------------------------------------------------------------------------------------------------------------------

%\subsection{Strong Ensemble Boosting}
\begin{frame}{Strong Ensemble Boosting}

\end{frame}

%----------------------------------------------------------------------------------------------------------------------------------

\section{Conclusion}
%\subsection{Results}
\begin{frame}{Conclusion: Results}

\end{frame}

\end{document}
